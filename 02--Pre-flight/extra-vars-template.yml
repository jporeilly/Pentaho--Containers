---
# Change default path to store Docker data
docker_daemon_graph: "/var/lib/docker"
  
# ===== ANSIBLE/KUBERNETES ACCESS CONFIGS =====
# Private Key for SSH
ansible_ssh_private_key_file: "~/.ssh/PLACEHOLDER_PEM_FILE_NAME"
ansible_ssh_private_key_file_name: "PLACEHOLDER_PEM_FILE_NAME"
ansible_user: PLACEHOLDER_ANSIBLE_USER

# used for certificate home for docker registry (copied to remote hosts)
local_user: installer
user_home: /home/installer

# Install metrics-server for K8s (top nodes, top pods)
metrics_server_enabled: true

# Ansible: Use the YAML callback plugin for cleaner output
stdout_callback: yaml

# Use the stdout_callback when running ad-hoc commands.
bin_ansible_callbacks: True

# ===== FOUNDRY CONTROL PLANE =====
# Python for pip and s3 cli
# Only set this to python3 if python3 is on all hosts.  At this time we only force it on the installer.
#ansible_python_interpreter: "/usr/bin/python"

# Master node to run Lumada installs after k8s has been deployed
# This node will also be used to host the shared registry for k8s
# NOTE:  this can install locally with a lot of values.   But it must be accessible
#        by name from the foundry UI (inside the pods) to complete the installation.
#        This oftem means the cerificate must be created with the external DNS name.
#        For example, "localhost" will install fine from the master node, but will
#        not be accessible from the other nodes, or the UI.
registry_domain: PLACEHOLDER_INSTALLER_NODE_HOSTNAME

# Docker Regsitry port
registry_port: 5000

# external load balancer for k8s masters
apiserver_loadbalancer_domain_name: "PLACEHOLDER_CLUSTER_NODE_HOSTNAME"

# =====  DNS ===== 
# Which name server are you using?
# If on AWS and HV you will likley need to change the DNS route
# to allow AWS private DNS lookup from inside the cluster.
change_dns: true
#dns_server: 169.254.169.253 # aws private dns
dns_server: 10.0.0.254 # skytap local dns

# =====  LDOS ===== 
nfs_host: 10.0.0.1
nfs_path: /data/pdi
install_type: LDOS
